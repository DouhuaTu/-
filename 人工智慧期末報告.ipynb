{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17f4501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 17.5174\n",
      "Epoch [2/10], Loss: 3.2639\n",
      "Epoch [3/10], Loss: 1.9642\n",
      "Epoch [4/10], Loss: 1.5923\n",
      "Epoch [5/10], Loss: 1.3670\n",
      "Epoch [6/10], Loss: 1.1758\n",
      "Epoch [7/10], Loss: 1.0175\n",
      "Epoch [8/10], Loss: 0.8843\n",
      "Epoch [9/10], Loss: 0.7874\n",
      "Epoch [10/10], Loss: 0.7298\n",
      "Total training time: 397.55 seconds\n",
      "Test RMSE: 0.0274\n",
      "Test PSNR: 31.6279\n"
     ]
    }
   ],
   "source": [
    "#單層卷積受限玻爾茲曼機模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "\n",
    "# 定義 ConvRBM 模型\n",
    "class ConvRBM(nn.Module):\n",
    "    def __init__(self, num_visible, num_hidden, kernel_size):\n",
    "        super(ConvRBM, self).__init__()\n",
    "        self.conv = nn.Conv2d(num_visible, num_hidden, kernel_size, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.unpool = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.deconv = nn.ConvTranspose2d(num_hidden, num_visible, kernel_size, stride=1, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.sigmoid(h)\n",
    "        h_pooled = self.pool(h)\n",
    "        h_unpooled = self.unpool(h_pooled)\n",
    "        x_reconstructed = self.deconv(h_unpooled)\n",
    "        x_reconstructed = self.sigmoid(x_reconstructed)\n",
    "        return x_reconstructed, h\n",
    "\n",
    "# 超參數設定\n",
    "num_visible = 1  # 輸入圖像通道數（灰階圖像為1）\n",
    "num_hidden = 32  # 隱藏層特徵圖的通道數\n",
    "kernel_size = 3  # 卷積核的大小\n",
    "\n",
    "# 載入訓練資料\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 初始化 ConvRBM 模型\n",
    "model = ConvRBM(num_visible, num_hidden, kernel_size)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練 ConvRBM 模型\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 訓練時間計算\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_data, _ = model(data)\n",
    "        loss = criterion(reconstructed_data, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print('Total training time: {:.2f} seconds'.format(training_time))\n",
    "\n",
    "# 測試集 RMSE 和 PSNR\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    mse_loss = 0\n",
    "    psnr = 0\n",
    "    num_samples = 0\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        reconstructed_data, _ = model(data)\n",
    "        mse_loss += criterion(reconstructed_data, data).item()\n",
    "        psnr += 10 * torch.log10(1. / criterion(reconstructed_data, data)).item()\n",
    "        num_samples += 1\n",
    "\n",
    "    mse_loss /= num_samples\n",
    "    psnr /= num_samples\n",
    "\n",
    "    print('Test RMSE: {:.4f}'.format(np.sqrt(mse_loss)))\n",
    "    print('Test PSNR: {:.4f}'.format(psnr))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c236bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 160.8797\n",
      "Epoch [2/10], Loss: 44.9903\n",
      "Epoch [3/10], Loss: 31.0271\n",
      "Epoch [4/10], Loss: 23.0282\n",
      "Epoch [5/10], Loss: 17.9684\n",
      "Epoch [6/10], Loss: 12.9549\n",
      "Epoch [7/10], Loss: 11.0559\n",
      "Epoch [8/10], Loss: 8.2944\n",
      "Epoch [9/10], Loss: 6.5463\n",
      "Epoch [10/10], Loss: 6.4619\n",
      "Total training time: 443.72 seconds\n",
      "Test Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "# 卷积神经网络模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 超参数设置\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 载入训练数据\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 初始化卷积神经网络模型\n",
    "model = ConvNet()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 转移到GPU上进行训练（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 训练时间计算\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print('Total training time: {:.2f} seconds'.format(training_time))\n",
    "\n",
    "# 测试集准确率\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Test Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c39cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.3242\n",
      "Epoch [1/10], Step [200/938], Loss: 0.3169\n",
      "Epoch [1/10], Step [300/938], Loss: 0.2012\n",
      "Epoch [1/10], Step [400/938], Loss: 0.1394\n",
      "Epoch [1/10], Step [500/938], Loss: 0.1725\n",
      "Epoch [1/10], Step [600/938], Loss: 0.0599\n",
      "Epoch [1/10], Step [700/938], Loss: 0.1911\n",
      "Epoch [1/10], Step [800/938], Loss: 0.2970\n",
      "Epoch [1/10], Step [900/938], Loss: 0.0143\n",
      "Epoch [2/10], Step [100/938], Loss: 0.0752\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0622\n",
      "Epoch [2/10], Step [300/938], Loss: 0.0240\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0325\n",
      "Epoch [2/10], Step [500/938], Loss: 0.0239\n",
      "Epoch [2/10], Step [600/938], Loss: 0.0250\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0474\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0139\n",
      "Epoch [2/10], Step [900/938], Loss: 0.0199\n",
      "Epoch [3/10], Step [100/938], Loss: 0.0159\n",
      "Epoch [3/10], Step [200/938], Loss: 0.0036\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0324\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0349\n",
      "Epoch [3/10], Step [500/938], Loss: 0.1048\n",
      "Epoch [3/10], Step [600/938], Loss: 0.0059\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0107\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0079\n",
      "Epoch [3/10], Step [900/938], Loss: 0.0361\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0044\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0038\n",
      "Epoch [4/10], Step [300/938], Loss: 0.0094\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0005\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0188\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0227\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0069\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0347\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0149\n",
      "Epoch [5/10], Step [100/938], Loss: 0.0088\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0870\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0042\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0010\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0063\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0838\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0308\n",
      "Epoch [5/10], Step [800/938], Loss: 0.1135\n",
      "Epoch [5/10], Step [900/938], Loss: 0.0141\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0027\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0085\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0258\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0083\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0715\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0032\n",
      "Epoch [6/10], Step [700/938], Loss: 0.0023\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0509\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0207\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0094\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0084\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0017\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0534\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0002\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0131\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0747\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0204\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0103\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0117\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0048\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0099\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0130\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0040\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0030\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0891\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0012\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0149\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0041\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0053\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0037\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0022\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0020\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0019\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0075\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0003\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0256\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0088\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0015\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0024\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0036\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0261\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0001\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0063\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0043\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0448\n",
      "Total training time: 432.94 seconds\n",
      "Test Accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "\n",
    "# 定義卷積神經網路模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 超參數設定\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 載入訓練資料\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 初始化卷積神經網路模型\n",
    "model = ConvNet()\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 訓練卷積神經網路模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 訓練時間計算\n",
    "start_time = time.time()\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向傳播和優化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print('Total training time: {:.2f} seconds'.format(training_time))\n",
    "\n",
    "# 測試集準確率\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Test Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acefe27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 888.8231\n",
      "Epoch [2/10], Loss: 886.8463\n",
      "Epoch [3/10], Loss: 886.8464\n",
      "Epoch [4/10], Loss: 886.8461\n",
      "Epoch [5/10], Loss: 886.8453\n",
      "Epoch [6/10], Loss: 886.8448\n",
      "Epoch [7/10], Loss: 886.8443\n",
      "Epoch [8/10], Loss: 886.8464\n",
      "Epoch [9/10], Loss: 886.8443\n",
      "Epoch [10/10], Loss: 886.8463\n",
      "Total training time: 169.24 seconds\n",
      "Test reconstruction error: 0.9457\n"
     ]
    }
   ],
   "source": [
    "# 稀疏編碼模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "\n",
    "# 定義稀疏編碼模型\n",
    "class SparseCoding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SparseCoding, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.encoder(x))\n",
    "        x_reconstructed = self.relu(self.decoder(h))\n",
    "        return x_reconstructed, h\n",
    "\n",
    "# 超參數設定\n",
    "input_size = 784  # MNIST 圖像尺寸為 28x28，展開為 784 的向量\n",
    "hidden_size = 32  # 隱藏層特徵數量\n",
    "\n",
    "# 載入訓練資料\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 初始化稀疏編碼模型\n",
    "model = SparseCoding(input_size, hidden_size)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練稀疏編碼模型\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 訓練時間計算\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0), -1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_data, _ = model(data)\n",
    "        loss = criterion(reconstructed_data, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print('Total training time: {:.2f} seconds'.format(training_time))\n",
    "\n",
    "# 測試集重建誤差\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstruction_error = 0\n",
    "    num_samples = 0\n",
    "    for data, _ in test_loader:\n",
    "        data = data.view(data.size(0), -1).to(device)\n",
    "        reconstructed_data, _ = model(data)\n",
    "        reconstruction_error += criterion(reconstructed_data, data).item()\n",
    "        num_samples += 1\n",
    "\n",
    "    reconstruction_error /= num_samples\n",
    "\n",
    "    print('Test reconstruction error: {:.4f}'.format(reconstruction_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3ddca76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input images must have the same dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7x/l6xcrf8d2rx9xgm8ttqsqslr0000gn/T/ipykernel_11734/2017167665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mbicubic_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mbicubic_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mbicubic_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicubic_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbicubic_rmse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/skimage/metrics/simple_metrics.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(image0, image1)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mcheck_shape_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_floats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mcheck_shape_equality\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;34m\"\"\"Raise an error if the shape do not match.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input images must have the same dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input images must have the same dimensions."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio, mean_squared_error\n",
    "from skimage.transform import resize\n",
    "\n",
    "# 生成训练图像\n",
    "width = 256\n",
    "height = 256\n",
    "\n",
    "# 生成随机灰度图像作为训练图像\n",
    "training_image = np.random.randint(0, 256, (height, width), dtype=np.uint8)\n",
    "\n",
    "# 设置超分辨率倍数\n",
    "scale_factor = 2\n",
    "\n",
    "# 使用Bicubic模型进行超解析度处理\n",
    "start_time = time.time()\n",
    "bicubic_image = cv2.resize(training_image, (width*scale_factor, height*scale_factor), interpolation=cv2.INTER_CUBIC)\n",
    "bicubic_time = time.time() - start_time\n",
    "bicubic_rmse = np.sqrt(mean_squared_error(training_image, bicubic_image))\n",
    "\n",
    "if bicubic_rmse == 0:\n",
    "    bicubic_psnr = float('inf')\n",
    "else:\n",
    "    bicubic_psnr = peak_signal_noise_ratio(training_image, bicubic_image)\n",
    "\n",
    "# 使用卷积受限玻尔兹曼机模型进行超解析度处理\n",
    "# 需要使用相应的库进行模型训练和图像重建\n",
    "# 这里只是一个示例，具体实现可能会有所不同\n",
    "\n",
    "# 使用卷积神经网络模型进行超解析度处理\n",
    "# 需要使用相应的库进行模型训练和图像重建\n",
    "# 这里只是一个示例，具体实现可能会有所不同\n",
    "\n",
    "# 使用稀疏编码模型进行超解析度处理\n",
    "start_time = time.time()\n",
    "# 实现稀疏编码模型，例如使用Lasso算法\n",
    "# 这里只是一个示例，具体实现可能会有所不同\n",
    "lasso_image = training_image  # 使用训练图像作为稀疏编码模型的结果\n",
    "sparse_coding_time = time.time() - start_time\n",
    "sparse_coding_rmse = np.sqrt(mean_squared_error(training_image, lasso_image))\n",
    "\n",
    "if sparse_coding_rmse == 0:\n",
    "    sparse_coding_psnr = float('inf')\n",
    "else:\n",
    "    sparse_coding_psnr = peak_signal_noise_ratio(training_image, lasso_image)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Bicubic模型:\")\n",
    "print(\"训练时间: %.2f 秒\" % bicubic_time)\n",
    "print(\"RMSE值: %.2f\" % bicubic_rmse)\n",
    "print(\"PSNR值: %.2f\" % bicubic_psnr)\n",
    "print()\n",
    "\n",
    "print(\"卷积受限玻尔兹曼机模型:\")\n",
    "# 打印训练时间、RMSE值和PSNR值\n",
    "print()\n",
    "\n",
    "print(\"卷积神经网络模型:\")\n",
    "# 打印训练时间、RMSE值和PSNR值\n",
    "print()\n",
    "\n",
    "print(\"稀疏编码模型:\")\n",
    "print(\"训练时间: %.2f 秒\" % sparse_coding_time)\n",
    "print(\"RMSE值: %.2f\" % sparse_coding_rmse)\n",
    "print(\"PSNR值: %.2f\" % sparse_coding_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c219f2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-macosx_10_16_x86_64.whl (53.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a92f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
